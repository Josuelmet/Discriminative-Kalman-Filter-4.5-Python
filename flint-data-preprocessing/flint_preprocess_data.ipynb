{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38957802-5543-44dc-8773-51d4a047d87e",
   "metadata": {},
   "source": [
    "# Flint 2012 DREAM Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cdb584d-3959-4c9f-9696-8912338981e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c7814-fb31-4d5f-88fc-93091e991768",
   "metadata": {},
   "source": [
    "### 1) Load data all at once to make loop run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b61e399-e8bf-458f-ae79-fcaa7ae29145",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.empty(5, dtype=object)\n",
    "\n",
    "for h in range(5):\n",
    "    files[h] = sc.loadmat(f'Flint_2012_e{h+1}.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651e53a-18df-42f6-99a4-68812279e839",
   "metadata": {},
   "source": [
    "### 2) Gather all data into two arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331b17c-cc86-41ca-964e-a6637d49f33f",
   "metadata": {},
   "source": [
    "#### Helper vstack function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0949e56-693d-4e1a-9b63-778a328a3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vstack(top, bottom):\n",
    "    if len(top) == 0:\n",
    "        return bottom # vstack doesn't work with empty array\n",
    "    else:\n",
    "        return np.vstack((top, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4168ed88-58b4-4b39-9706-9eaf02128435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrangling subject 0... \n",
      "Wrangling subject 0... \n",
      "Wrangling subject 1... \n",
      "Wrangling subject 0... \n",
      "Wrangling subject 1... \n",
      "Wrangling subject 2... \n",
      "Wrangling subject 3... \n",
      "Wrangling subject 0... \n",
      "Wrangling subject 1... \n",
      "Wrangling subject 2... \n",
      "Wrangling subject 0... \n",
      "Wrangling subject 1... \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The data-wrangling code here is a bit messy, but it makes more sense when viewed as the\n",
    "Python equivalent of the work done by the original authors.\n",
    "'''\n",
    "\n",
    "dataset_velocities = []\n",
    "dataset_spikes = []\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    nSubject = len(file['Subject'])\n",
    "\n",
    "\n",
    "    # For each subject:\n",
    "    for i in range(nSubject):\n",
    "        print(f'Wrangling subject {i}... ')\n",
    "\n",
    "        # Get all data pertaining to the i-th subject in this experiment.\n",
    "        # Extra [0] added because Python yields file['Subject'] as a 2D array.\n",
    "        Subject_i = file['Subject'][i][0]\n",
    "\n",
    "        nTrial = len(Subject_i['Trial'])\n",
    "\n",
    "        # Get the number of neurons from the first trial.\n",
    "        # Extra [0] added at the end because Python wrapped the ['Neuron'] data in a 1-element array.\n",
    "        nNeuron = len(Subject_i['Trial'][0]['Neuron'][0])\n",
    "\n",
    "        \n",
    "        \n",
    "        vel = np.array([])\n",
    "        spk = np.array([])\n",
    "\n",
    "        # Agglomerate over trials\n",
    "        for j in range(nTrial):\n",
    "\n",
    "            Trial_j = Subject_i['Trial'][j]\n",
    "\n",
    "            # Get [SOMETHING]\n",
    "            # Extra [0] added because Python wrapped the ['Time'] data in a 1-element array.\n",
    "            beats = len(Trial_j['Time'][0])\n",
    "\n",
    "            # vel and Trial_j['HandVel'][0] are ?x3 arrays.\n",
    "            # ? is related to how many timestamps there are, and 3 corresponds to the 3D velocity.\n",
    "            # Extra [0] added because Python wrapped the ['HandVel'] data in a 1-element array.    \n",
    "            vel = vstack(vel, Trial_j['HandVel'][0])\n",
    "\n",
    "\n",
    "            spk_k = np.zeros((beats, nNeuron))\n",
    "\n",
    "            for k in range(nNeuron):\n",
    "\n",
    "                # Spike binning from the k-th neuron.\n",
    "\n",
    "                # The two extra [0] were added because Python wrapped that ['Neuron'] and ['Spike'] data in 1-element arrays.\n",
    "                spiketimes = Trial_j['Neuron'][0][k]['Spike'][0]\n",
    "\n",
    "                # If there are no spiketimes, skip the k-th neuron.\n",
    "                if len(spiketimes) > 0:\n",
    "                    # The [:,0] was added because Python wrapped the 1-D spiketime data as a 2D column vector.\n",
    "                    # The [0] at the end is to only keep bin counts, not bin intervals.\n",
    "                    spk_k[:,k] = np.histogram(spiketimes[:,0], bins=beats)[0]\n",
    "\n",
    "            spk = vstack(spk, spk_k)\n",
    "\n",
    "\n",
    "        # Only keep the first two dimensions of 3D velocity, since the other was always constant (since the motion was 2D).\n",
    "        vel = vel[:, :2]\n",
    "\n",
    "\n",
    "        # Save the data from the i-th subject and h-th Flint file to its own unique spot in the dataset_? arrays.\n",
    "        dataset_velocities.append(vel)\n",
    "        dataset_spikes.append(spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9c5e3-fd97-4e46-ac19-3a12944870e2",
   "metadata": {},
   "source": [
    "### 3) Preprocess (filter) the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06783f82-220d-416c-8f66-6510da5b7388",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_velocities = np.array(dataset_velocities, dtype=object)\n",
    "dataset_spikes = np.array(dataset_spikes, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ae4e0a-604d-43e7-b789-e2ed3023ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSets = len(dataset_velocities)\n",
    "\n",
    "# Make arrays for preprocessed velocities + spikes\n",
    "procd_velocities = []\n",
    "procd_spikes = []\n",
    "\n",
    "\n",
    "for i in range(nSets):\n",
    "    vel = dataset_velocities[i]\n",
    "    spk = dataset_spikes[i]\n",
    "    \n",
    "    # Downsample data to 100ms bins\n",
    "    idx = np.arange(9, len(vel), 10) # step = 10 to ensure 100ms binlength.\n",
    "    \n",
    "    moving_sum = spk.cumsum(axis=0) # Calculate vertical cumsum\n",
    "    moving_sum[10:] = moving_sum[10:] - moving_sum[:-10] # Use cumsum to get moving sum with window length 10.\n",
    "    spk_ds = moving_sum[idx]\n",
    "    \n",
    "    vel_ds = vel[idx - 5] # Get the velocity reading halfway between each entry of spk_ds.\n",
    "    \n",
    "    # Hit neural data with PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    spk_pca = pca.fit_transform(spk_ds) # spk_pca is the dimensionalty-reduced array of neural activity.\n",
    "    \n",
    "    # z-score the neural data\n",
    "    spk_z = zscore(spk_pca, ddof=1)\n",
    "    \n",
    "    \n",
    "    # Store the data\n",
    "    procd_velocities.append(vel_ds)\n",
    "    procd_spikes.append(spk_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b86b5-b993-48e4-97ac-6802f8609407",
   "metadata": {},
   "source": [
    "### 4) Store the data in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4669a6cf-11f9-436b-8e3d-91d63e36ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "procd_velocities = np.array(procd_velocities, dtype=object)\n",
    "procd_spikes = np.array(procd_spikes, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9edf51-6f60-455a-9e7f-0a502c5546ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('procd_velocities', procd_velocities)\n",
    "np.save('procd_spikes', procd_spikes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
